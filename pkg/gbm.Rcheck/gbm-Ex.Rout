
R version 2.7.1 (2008-06-23)
Copyright (C) 2008 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ### * <HEADER>
> ###
> attach(NULL, name = "CheckExEnv")
> assign("nameEx", 
+        local({
+ 	   s <- "__{must remake R-ex/*.R}__"
+            function(new) {
+                if(!missing(new)) s <<- new else s
+            }
+        }),
+        pos = "CheckExEnv")
> ## Add some hooks to label plot pages for base and grid graphics
> assign("base_plot_hook",
+        function() {
+            pp <- par(c("mfg","mfcol","oma","mar"))
+            if(all(pp$mfg[1:2] == c(1, pp$mfcol[2]))) {
+                outer <- (oma4 <- pp$oma[4]) > 0; mar4 <- pp$mar[4]
+                mtext(sprintf("help(\"%s\")", nameEx()), side = 4,
+                      line = if(outer)max(1, oma4 - 1) else min(1, mar4 - 1),
+                outer = outer, adj = 1, cex = .8, col = "orchid", las=3)
+            }
+        },
+        pos = "CheckExEnv")
> assign("grid_plot_hook",
+        function() {
+            grid::pushViewport(grid::viewport(width=grid::unit(1, "npc") - 
+                               grid::unit(1, "lines"), x=0, just="left"))
+            grid::grid.text(sprintf("help(\"%s\")", nameEx()),
+                            x=grid::unit(1, "npc") + grid::unit(0.5, "lines"),
+                            y=grid::unit(0.8, "npc"), rot=90,
+                            gp=grid::gpar(col="orchid"))
+        },
+        pos = "CheckExEnv")
> setHook("plot.new",     get("base_plot_hook", pos = "CheckExEnv"))
> setHook("persp",        get("base_plot_hook", pos = "CheckExEnv"))
> setHook("grid.newpage", get("grid_plot_hook", pos = "CheckExEnv"))
> assign("cleanEx",
+        function(env = .GlobalEnv) {
+ 	   rm(list = ls(envir = env, all.names = TRUE), envir = env)
+            RNGkind("default", "default")
+ 	   set.seed(1)
+    	   options(warn = 1)
+ 	   .CheckExEnv <- as.environment("CheckExEnv")
+ 	   delayedAssign("T", stop("T used instead of TRUE"),
+ 		  assign.env = .CheckExEnv)
+ 	   delayedAssign("F", stop("F used instead of FALSE"),
+ 		  assign.env = .CheckExEnv)
+ 	   sch <- search()
+ 	   newitems <- sch[! sch %in% .oldSearch]
+ 	   for(item in rev(newitems))
+                eval(substitute(detach(item), list(item=item)))
+ 	   missitems <- .oldSearch[! .oldSearch %in% sch]
+ 	   if(length(missitems))
+ 	       warning("items ", paste(missitems, collapse=", "),
+ 		       " have been removed from the search path")
+        },
+        pos = "CheckExEnv")
> assign("ptime", proc.time(), pos = "CheckExEnv")
> ## at least one package changes these via ps.options(), so do this
> ## before loading the package.
> ## Use postscript as incomplete files may be viewable, unlike PDF.
> ## Choose a size that is close to on-screen devices, fix paper
> ps.options(width = 7, height = 7, paper = "a4", reset = TRUE)
> grDevices::postscript("gbm-Ex.ps")
> 		      
> assign("par.postscript", graphics::par(no.readonly = TRUE), pos = "CheckExEnv")
> options(contrasts = c(unordered = "contr.treatment", ordered = "contr.poly"))
> options(warn = 1)    
> library('gbm')
Loading required package: survival
Loading required package: splines
Loading required package: lattice
Loaded gbm
This is an experimental version: please report bugs to
harry.southworth at gmail dot com
> 
> assign(".oldSearch", search(), pos = 'CheckExEnv')
> assign(".oldNS", loadedNamespaces(), pos = 'CheckExEnv')
> cleanEx(); nameEx("calibrate.plot")
> ### * calibrate.plot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: calibrate.plot
> ### Title: Calibration plot
> ### Aliases: calibrate.plot
> ### Keywords: hplot
> 
> ### ** Examples
> 
> library(rpart)
> data(kyphosis)
> y <- as.numeric(kyphosis$Kyphosis)-1
> x <- kyphosis$Age
> glm1 <- glm(y~poly(x,2),family=binomial)
> p <- predict(glm1,type="response")
> calibrate.plot(y, p, xlim=c(0,0.6), ylim=c(0,0.6))
> 
> 
> 
> cleanEx(); nameEx("gbm")
> ### * gbm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gbm
> ### Title: Generalized Boosted Regression Modeling
> ### Aliases: gbm gbm.more gbm.fit
> ### Keywords: models nonlinear survival nonparametric tree
> 
> ### ** Examples
> 
> # A least squares regression example
> # create some data
> 
> N <- 1000
> X1 <- runif(N)
> X2 <- 2*runif(N)
> X3 <- ordered(sample(letters[1:4],N,replace=TRUE),levels=letters[4:1])
> X4 <- factor(sample(letters[1:6],N,replace=TRUE))
> X5 <- factor(sample(letters[1:3],N,replace=TRUE))
> X6 <- 3*runif(N)
> mu <- c(-1,0,1,2)[as.numeric(X3)]
> 
> SNR <- 10 # signal-to-noise ratio
> Y <- X1**1.5 + 2 * (X2**.5) + mu
> sigma <- sqrt(var(Y)/SNR)
> Y <- Y + rnorm(N,0,sigma)
> 
> # introduce some missing values
> X1[sample(1:N,size=500)] <- NA
> X4[sample(1:N,size=300)] <- NA
> 
> data <- data.frame(Y=Y,X1=X1,X2=X2,X3=X3,X4=X4,X5=X5,X6=X6)
> 
> # fit initial model
> gbm1 <- gbm(Y~X1+X2+X3+X4+X5+X6,         # formula
+     data=data,                   # dataset
+     var.monotone=c(0,0,0,0,0,0), # -1: monotone decrease,
+                                  # +1: monotone increase,
+                                  #  0: no monotone restrictions
+     distribution="gaussian",     # bernoulli, adaboost, gaussian,
+                                  # poisson, coxph, and quantile available
+     n.trees=3000,                # number of trees
+     shrinkage=0.005,             # shrinkage or learning rate,
+                                  # 0.001 to 0.1 usually work
+     interaction.depth=3,         # 1: additive model, 2: two-way interactions, etc.
+     bag.fraction = 0.5,          # subsampling fraction, 0.5 is probably best
+     train.fraction = 0.5,        # fraction of data for training,
+                                  # first train.fraction*N used for training
+     n.minobsinnode = 10,         # minimum total weight needed in each node
+     cv.folds = 5,                # do 5-fold cross-validation
+     keep.data=TRUE,              # keep a copy of the dataset with the object
+     verbose=TRUE)                # print out progress
CV: 1 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.9445          1.9168     0.0050    0.0136
     2        1.9299          1.9037     0.0050    0.0136
     3        1.9162          1.8913     0.0050    0.0137
     4        1.9017          1.8780     0.0050    0.0138
     5        1.8873          1.8648     0.0050    0.0137
     6        1.8730          1.8519     0.0050    0.0143
     7        1.8592          1.8396     0.0050    0.0140
     8        1.8465          1.8282     0.0050    0.0121
     9        1.8335          1.8165     0.0050    0.0126
    10        1.8200          1.8043     0.0050    0.0137
   100        1.0187          1.0809     0.0050    0.0057
   200        0.6127          0.7167     0.0050    0.0024
   300        0.4256          0.5539     0.0050    0.0012
   400        0.3307          0.4686     0.0050    0.0005
   500        0.2764          0.4186     0.0050    0.0003
   600        0.2449          0.3873     0.0050    0.0000
   700        0.2240          0.3669     0.0050    0.0001
   800        0.2105          0.3552     0.0050    0.0000
   900        0.2009          0.3452     0.0050   -0.0000
  1000        0.1932          0.3397     0.0050   -0.0000
  1100        0.1872          0.3356     0.0050   -0.0000
  1200        0.1815          0.3340     0.0050   -0.0001
  1300        0.1768          0.3323     0.0050   -0.0000
  1400        0.1727          0.3318     0.0050   -0.0001
  1500        0.1688          0.3318     0.0050   -0.0001
  1600        0.1650          0.3307     0.0050   -0.0001
  1700        0.1616          0.3318     0.0050   -0.0000
  1800        0.1585          0.3312     0.0050   -0.0000
  1900        0.1557          0.3309     0.0050   -0.0001
  2000        0.1527          0.3312     0.0050   -0.0000
  2100        0.1502          0.3320     0.0050   -0.0001
  2200        0.1476          0.3321     0.0050   -0.0001
  2300        0.1450          0.3330     0.0050   -0.0000
  2400        0.1426          0.3337     0.0050   -0.0000
  2500        0.1403          0.3346     0.0050   -0.0000
  2600        0.1382          0.3345     0.0050   -0.0000
  2700        0.1363          0.3352     0.0050   -0.0000
  2800        0.1344          0.3357     0.0050   -0.0001
  2900        0.1324          0.3361     0.0050   -0.0000
  3000        0.1305          0.3361     0.0050   -0.0000

CV: 2 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.9199          2.0328     0.0050    0.0138
     2        1.9056          2.0179     0.0050    0.0141
     3        1.8921          2.0032     0.0050    0.0139
     4        1.8783          1.9884     0.0050    0.0141
     5        1.8645          1.9733     0.0050    0.0139
     6        1.8518          1.9594     0.0050    0.0127
     7        1.8393          1.9466     0.0050    0.0128
     8        1.8268          1.9339     0.0050    0.0133
     9        1.8132          1.9190     0.0050    0.0119
    10        1.8008          1.9053     0.0050    0.0119
   100        1.0202          1.0863     0.0050    0.0054
   200        0.6247          0.6741     0.0050    0.0022
   300        0.4410          0.4843     0.0050    0.0012
   400        0.3452          0.3868     0.0050    0.0003
   500        0.2912          0.3354     0.0050    0.0003
   600        0.2601          0.3091     0.0050    0.0002
   700        0.2391          0.2933     0.0050    0.0001
   800        0.2251          0.2851     0.0050    0.0000
   900        0.2146          0.2797     0.0050   -0.0000
  1000        0.2065          0.2783     0.0050    0.0000
  1100        0.1998          0.2767     0.0050   -0.0000
  1200        0.1941          0.2762     0.0050   -0.0001
  1300        0.1890          0.2757     0.0050   -0.0001
  1400        0.1845          0.2766     0.0050   -0.0000
  1500        0.1806          0.2772     0.0050   -0.0001
  1600        0.1769          0.2774     0.0050   -0.0001
  1700        0.1735          0.2779     0.0050   -0.0000
  1800        0.1702          0.2784     0.0050   -0.0001
  1900        0.1671          0.2788     0.0050   -0.0000
  2000        0.1641          0.2782     0.0050   -0.0001
  2100        0.1612          0.2788     0.0050   -0.0001
  2200        0.1585          0.2795     0.0050   -0.0000
  2300        0.1561          0.2798     0.0050   -0.0000
  2400        0.1533          0.2803     0.0050   -0.0001
  2500        0.1510          0.2810     0.0050   -0.0001
  2600        0.1488          0.2813     0.0050   -0.0000
  2700        0.1467          0.2815     0.0050   -0.0001
  2800        0.1447          0.2815     0.0050   -0.0001
  2900        0.1426          0.2815     0.0050   -0.0001
  3000        0.1405          0.2818     0.0050   -0.0000

CV: 3 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.9872          1.7427     0.0050    0.0140
     2        1.9735          1.7311     0.0050    0.0141
     3        1.9596          1.7189     0.0050    0.0138
     4        1.9463          1.7070     0.0050    0.0149
     5        1.9327          1.6948     0.0050    0.0132
     6        1.9188          1.6815     0.0050    0.0127
     7        1.9050          1.6694     0.0050    0.0127
     8        1.8920          1.6571     0.0050    0.0137
     9        1.8799          1.6460     0.0050    0.0127
    10        1.8675          1.6341     0.0050    0.0138
   100        1.0646          0.9232     0.0050    0.0055
   200        0.6511          0.5666     0.0050    0.0023
   300        0.4597          0.4019     0.0050    0.0009
   400        0.3595          0.3185     0.0050    0.0007
   500        0.3026          0.2757     0.0050    0.0002
   600        0.2690          0.2540     0.0050    0.0002
   700        0.2476          0.2435     0.0050    0.0000
   800        0.2332          0.2373     0.0050    0.0001
   900        0.2222          0.2353     0.0050    0.0000
  1000        0.2143          0.2352     0.0050   -0.0001
  1100        0.2077          0.2348     0.0050   -0.0001
  1200        0.2022          0.2359     0.0050   -0.0000
  1300        0.1972          0.2370     0.0050   -0.0000
  1400        0.1931          0.2370     0.0050   -0.0001
  1500        0.1889          0.2381     0.0050   -0.0000
  1600        0.1851          0.2385     0.0050   -0.0000
  1700        0.1816          0.2382     0.0050   -0.0001
  1800        0.1783          0.2400     0.0050   -0.0000
  1900        0.1752          0.2406     0.0050   -0.0001
  2000        0.1721          0.2411     0.0050   -0.0001
  2100        0.1695          0.2424     0.0050   -0.0001
  2200        0.1667          0.2429     0.0050   -0.0001
  2300        0.1641          0.2426     0.0050   -0.0000
  2400        0.1618          0.2431     0.0050   -0.0001
  2500        0.1592          0.2436     0.0050   -0.0001
  2600        0.1569          0.2432     0.0050   -0.0000
  2700        0.1548          0.2430     0.0050   -0.0001
  2800        0.1526          0.2433     0.0050   -0.0000
  2900        0.1502          0.2446     0.0050   -0.0000
  3000        0.1482          0.2454     0.0050   -0.0001

CV: 4 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.9312          1.9694     0.0050    0.0151
     2        1.9175          1.9557     0.0050    0.0140
     3        1.9039          1.9424     0.0050    0.0138
     4        1.8898          1.9285     0.0050    0.0135
     5        1.8768          1.9159     0.0050    0.0129
     6        1.8630          1.9028     0.0050    0.0139
     7        1.8499          1.8905     0.0050    0.0119
     8        1.8360          1.8772     0.0050    0.0127
     9        1.8229          1.8639     0.0050    0.0134
    10        1.8103          1.8518     0.0050    0.0137
   100        1.0313          1.0654     0.0050    0.0053
   200        0.6366          0.6396     0.0050    0.0024
   300        0.4540          0.4478     0.0050    0.0012
   400        0.3589          0.3524     0.0050    0.0005
   500        0.3043          0.2982     0.0050    0.0003
   600        0.2712          0.2684     0.0050    0.0001
   700        0.2513          0.2533     0.0050   -0.0001
   800        0.2374          0.2453     0.0050   -0.0000
   900        0.2268          0.2395     0.0050   -0.0000
  1000        0.2188          0.2381     0.0050   -0.0000
  1100        0.2121          0.2376     0.0050    0.0000
  1200        0.2063          0.2351     0.0050   -0.0000
  1300        0.2014          0.2343     0.0050   -0.0001
  1400        0.1969          0.2332     0.0050   -0.0000
  1500        0.1929          0.2325     0.0050   -0.0000
  1600        0.1895          0.2319     0.0050   -0.0001
  1700        0.1860          0.2320     0.0050   -0.0001
  1800        0.1829          0.2327     0.0050   -0.0000
  1900        0.1799          0.2316     0.0050   -0.0001
  2000        0.1769          0.2315     0.0050   -0.0001
  2100        0.1741          0.2316     0.0050   -0.0001
  2200        0.1712          0.2305     0.0050    0.0000
  2300        0.1686          0.2300     0.0050   -0.0001
  2400        0.1661          0.2301     0.0050   -0.0001
  2500        0.1637          0.2299     0.0050   -0.0001
  2600        0.1615          0.2300     0.0050   -0.0001
  2700        0.1594          0.2294     0.0050   -0.0000
  2800        0.1572          0.2291     0.0050   -0.0000
  2900        0.1553          0.2286     0.0050   -0.0001
  3000        0.1535          0.2288     0.0050   -0.0001

CV: 5 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.9079          2.0652     0.0050    0.0135
     2        1.8953          2.0510     0.0050    0.0130
     3        1.8828          2.0369     0.0050    0.0123
     4        1.8697          2.0229     0.0050    0.0119
     5        1.8570          2.0091     0.0050    0.0139
     6        1.8442          1.9954     0.0050    0.0126
     7        1.8308          1.9807     0.0050    0.0139
     8        1.8184          1.9668     0.0050    0.0110
     9        1.8060          1.9525     0.0050    0.0125
    10        1.7941          1.9392     0.0050    0.0109
   100        1.0268          1.1019     0.0050    0.0054
   200        0.6292          0.6693     0.0050    0.0022
   300        0.4431          0.4740     0.0050    0.0012
   400        0.3469          0.3791     0.0050    0.0006
   500        0.2923          0.3317     0.0050    0.0004
   600        0.2596          0.3057     0.0050    0.0002
   700        0.2390          0.2915     0.0050    0.0001
   800        0.2247          0.2862     0.0050    0.0000
   900        0.2144          0.2819     0.0050   -0.0001
  1000        0.2064          0.2804     0.0050   -0.0000
  1100        0.1998          0.2804     0.0050   -0.0001
  1200        0.1940          0.2813     0.0050   -0.0001
  1300        0.1892          0.2830     0.0050   -0.0000
  1400        0.1850          0.2841     0.0050   -0.0001
  1500        0.1811          0.2849     0.0050   -0.0001
  1600        0.1776          0.2851     0.0050   -0.0001
  1700        0.1740          0.2858     0.0050   -0.0001
  1800        0.1710          0.2855     0.0050   -0.0001
  1900        0.1680          0.2869     0.0050   -0.0001
  2000        0.1651          0.2876     0.0050   -0.0001
  2100        0.1624          0.2881     0.0050   -0.0001
  2200        0.1598          0.2886     0.0050   -0.0001
  2300        0.1574          0.2885     0.0050   -0.0000
  2400        0.1550          0.2880     0.0050   -0.0001
  2500        0.1528          0.2884     0.0050   -0.0001
  2600        0.1505          0.2901     0.0050   -0.0001
  2700        0.1482          0.2908     0.0050   -0.0001
  2800        0.1461          0.2913     0.0050   -0.0000
  2900        0.1441          0.2924     0.0050   -0.0001
  3000        0.1422          0.2937     0.0050   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.9384          2.1350     0.0050    0.0145
     2        1.9249          2.1215     0.0050    0.0139
     3        1.9119          2.1085     0.0050    0.0140
     4        1.8983          2.0947     0.0050    0.0131
     5        1.8847          2.0810     0.0050    0.0131
     6        1.8713          2.0675     0.0050    0.0135
     7        1.8586          2.0545     0.0050    0.0130
     8        1.8462          2.0420     0.0050    0.0123
     9        1.8333          2.0288     0.0050    0.0126
    10        1.8204          2.0159     0.0050    0.0131
   100        1.0403          1.2156     0.0050    0.0059
   200        0.6378          0.7848     0.0050    0.0023
   300        0.4505          0.5727     0.0050    0.0010
   400        0.3528          0.4559     0.0050    0.0007
   500        0.2984          0.3869     0.0050    0.0002
   600        0.2662          0.3469     0.0050    0.0000
   700        0.2459          0.3229     0.0050    0.0001
   800        0.2323          0.3062     0.0050    0.0000
   900        0.2229          0.2968     0.0050   -0.0000
  1000        0.2153          0.2901     0.0050   -0.0001
  1100        0.2091          0.2857     0.0050   -0.0000
  1200        0.2041          0.2826     0.0050   -0.0001
  1300        0.1997          0.2812     0.0050   -0.0000
  1400        0.1953          0.2799     0.0050   -0.0000
  1500        0.1920          0.2798     0.0050   -0.0000
  1600        0.1887          0.2806     0.0050   -0.0001
  1700        0.1855          0.2808     0.0050   -0.0001
  1800        0.1825          0.2814     0.0050   -0.0000
  1900        0.1797          0.2822     0.0050   -0.0000
  2000        0.1769          0.2828     0.0050   -0.0000
  2100        0.1744          0.2834     0.0050   -0.0001
  2200        0.1720          0.2842     0.0050   -0.0000
  2300        0.1697          0.2849     0.0050   -0.0001
  2400        0.1673          0.2857     0.0050   -0.0000
  2500        0.1650          0.2869     0.0050   -0.0000
  2600        0.1630          0.2885     0.0050   -0.0000
  2700        0.1610          0.2891     0.0050   -0.0000
  2800        0.1589          0.2896     0.0050   -0.0001
  2900        0.1569          0.2906     0.0050   -0.0001
  3000        0.1550          0.2916     0.0050   -0.0001

> 
> # check performance using an out-of-bag estimator
> # OOB underestimates the optimal number of iterations
> best.iter <- gbm.perf(gbm1,method="OOB")
Warning in gbm.perf(gbm1, method = "OOB") :
  OOB generally underestimates the optimal number of iterations although predictive performance is reasonably competitive. Using cv.folds>0 when calling gbm usually results in improved predictive performance.
> print(best.iter)
[1] 806
> 
> # check performance using a 50% heldout test set
> best.iter <- gbm.perf(gbm1,method="test")
> print(best.iter)
[1] 1409
> 
> # check performance using 5-fold cross-validation
> best.iter <- gbm.perf(gbm1,method="cv")
> print(best.iter)
[1] 1226
> 
> # plot the performance
> # plot variable influence
> summary(gbm1,n.trees=1)         # based on the first tree
   var  rel.inf
X3  X3 70.98875
X2  X2 29.01125
X1  X1  0.00000
X4  X4  0.00000
X5  X5  0.00000
X6  X6  0.00000
> summary(gbm1,n.trees=best.iter) # based on the estimated best number of trees
   var    rel.inf
X3  X3 66.4787449
X2  X2 27.5182342
X1  X1  3.4947383
X4  X4  1.2183214
X6  X6  1.1357839
X5  X5  0.1541774
> 
> # compactly print the first and last trees for curiosity
> print(pretty.gbm.tree(gbm1,1))
  SplitVar SplitCodePred LeftNode RightNode MissingNode ErrorReduction Weight
0        2  1.500000e+00        1         5           9      264.82193    250
1        1  7.548380e-01        2         3           4       47.71784    121
2       -1 -9.061111e-03       -1        -1          -1        0.00000     49
3       -1 -2.664664e-03       -1        -1          -1        0.00000     72
4       -1 -5.254961e-03       -1        -1          -1        0.00000    121
5        1  7.105657e-01        6         7           8       60.50796    129
6       -1  8.754679e-04       -1        -1          -1        0.00000     52
7       -1  7.856572e-03       -1        -1          -1        0.00000     77
8       -1  5.042483e-03       -1        -1          -1        0.00000    129
9       -1  5.852038e-05       -1        -1          -1        0.00000    250
     Prediction
0  5.852038e-05
1 -5.254961e-03
2 -9.061111e-03
3 -2.664664e-03
4 -5.254961e-03
5  5.042483e-03
6  8.754679e-04
7  7.856572e-03
8  5.042483e-03
9  5.852038e-05
> print(pretty.gbm.tree(gbm1,gbm1$n.trees))
  SplitVar SplitCodePred LeftNode RightNode MissingNode ErrorReduction Weight
0        5  2.773044e+00        1         8           9      0.8041567    250
1        4  1.752000e+03        2         3           7      0.4174088    236
2       -1 -3.322516e-04       -1        -1          -1      0.0000000     76
3        0  1.097308e-01        4         5           6      0.6029726    160
4       -1 -7.743003e-04       -1        -1          -1      0.0000000     11
5       -1 -7.621223e-06       -1        -1          -1      0.0000000     76
6       -1  3.827509e-04       -1        -1          -1      0.0000000     73
7       -1 -2.714758e-05       -1        -1          -1      0.0000000    236
8       -1  1.206214e-03       -1        -1          -1      0.0000000     14
9       -1  4.192066e-05       -1        -1          -1      0.0000000    250
     Prediction
0  4.192066e-05
1 -2.714758e-05
2 -3.322516e-04
3  1.177769e-04
4 -7.743003e-04
5 -7.621223e-06
6  3.827509e-04
7 -2.714758e-05
8  1.206214e-03
9  4.192066e-05
> 
> # make some new data
> N <- 1000
> X1 <- runif(N)
> X2 <- 2*runif(N)
> X3 <- ordered(sample(letters[1:4],N,replace=TRUE))
> X4 <- factor(sample(letters[1:6],N,replace=TRUE))
> X5 <- factor(sample(letters[1:3],N,replace=TRUE))
> X6 <- 3*runif(N)
> mu <- c(-1,0,1,2)[as.numeric(X3)]
> 
> Y <- X1**1.5 + 2 * (X2**.5) + mu + rnorm(N,0,sigma)
> 
> data2 <- data.frame(Y=Y,X1=X1,X2=X2,X3=X3,X4=X4,X5=X5,X6=X6)
> 
> # predict on the new data using "best" number of trees
> # f.predict generally will be on the canonical scale (logit,log,etc.)
> f.predict <- predict.gbm(gbm1,data2,best.iter)
> 
> # least squares error
> print(sum((data2$Y-f.predict)^2))
[1] 236.3234
> 
> # create marginal plots
> # plot variable X1,X2,X3 after "best" iterations
> par(mfrow=c(1,3))
> plot.gbm(gbm1,1,best.iter)
> plot.gbm(gbm1,2,best.iter)
> plot.gbm(gbm1,3,best.iter)
> par(mfrow=c(1,1))
> # contour plot of variables 1 and 2 after "best" iterations
> plot.gbm(gbm1,1:2,best.iter)
> # lattice plot of variables 2 and 3
> plot.gbm(gbm1,2:3,best.iter)
> # lattice plot of variables 3 and 4
> plot.gbm(gbm1,3:4,best.iter)
> 
> # 3-way plots
> plot.gbm(gbm1,c(1,2,6),best.iter,cont=20)
> plot.gbm(gbm1,1:3,best.iter)
> plot.gbm(gbm1,2:4,best.iter)
> plot.gbm(gbm1,3:5,best.iter)
> 
> # do another 100 iterations
> gbm2 <- gbm.more(gbm1,100,
+                  verbose=FALSE) # stop printing detailed progress
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx(); nameEx("print.gbm")
> ### * print.gbm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: print.gbm
> ### Title: ~~function to do ... ~~
> ### Aliases: print.gbm
> ### Keywords: models nonlinear survival nonparametric tree
> 
> ### ** Examples
> 
> library( gbm )
> data( iris )
> iris.mod <- gbm( Species ~ ., distribution="kclass", data=iris,
+                  n.trees=2000, shrinkage=.01, cv.folds=5 )
CV: 1 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986          1.0986     0.0100    0.0323
     2        1.0771          1.0796     0.0100    0.0294
     3        1.0556          1.0610     0.0100    0.0320
     4        1.0349          1.0420     0.0100    0.0302
     5        1.0158          1.0251     0.0100    0.0280
     6        0.9974          1.0086     0.0100    0.0277
     7        0.9791          0.9920     0.0100    0.0246
     8        0.9620          0.9765     0.0100    0.0272
     9        0.9442          0.9591     0.0100    0.0248
    10        0.9262          0.9438     0.0100    0.0240
   100        0.2442          0.3628     0.0100    0.0047
   200        0.0821          0.2599     0.0100    0.0002
   300        0.0410          0.2713     0.0100    0.0001
   400        0.0238          0.3050     0.0100    0.0001
   500        0.0150          0.3433     0.0100   -0.0000
   600        0.0102          0.3921     0.0100   -0.0001
   700        0.0077          0.4394     0.0100   -0.0001
   800        0.0056          0.4809     0.0100   -0.0000
   900        0.0041          0.5231     0.0100   -0.0000
  1000        0.0031          0.5696     0.0100   -0.0000
  1100        0.0024          0.6313     0.0100   -0.0000
  1200        0.0019          0.6702     0.0100   -0.0000
  1300        0.0016          0.7148     0.0100   -0.0000
  1400        0.0013          0.7686     0.0100   -0.0000
  1500        0.0009          0.8175     0.0100   -0.0000
  1600        0.0008          0.8625     0.0100   -0.0000
  1700        0.0007          0.9086     0.0100   -0.0000
  1800        0.0006          0.9482     0.0100   -0.0000
  1900        0.0005          0.9870     0.0100   -0.0000
  2000        0.0004          1.0248     0.0100   -0.0000

CV: 2 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986          1.0986     0.0100    0.0319
     2        1.0784          1.0782     0.0100    0.0302
     3        1.0585          1.0590     0.0100    0.0302
     4        1.0384          1.0386     0.0100    0.0293
     5        1.0196          1.0195     0.0100    0.0270
     6        1.0014          1.0010     0.0100    0.0284
     7        0.9839          0.9841     0.0100    0.0268
     8        0.9660          0.9662     0.0100    0.0266
     9        0.9489          0.9496     0.0100    0.0243
    10        0.9322          0.9326     0.0100    0.0235
   100        0.2749          0.2594     0.0100    0.0038
   200        0.1213          0.0961     0.0100    0.0005
   300        0.0802          0.0498     0.0100    0.0001
   400        0.0641          0.0342     0.0100   -0.0003
   500        0.0551          0.0299     0.0100   -0.0001
   600        0.0480          0.0251     0.0100   -0.0010
   700        0.0427          0.0230     0.0100   -0.0003
   800        0.0379          0.0182     0.0100   -0.0004
   900        0.0341          0.0152     0.0100   -0.0001
  1000        0.0311          0.0144     0.0100   -0.0006
  1100        0.0285          0.0140     0.0100   -0.0002
  1200        0.0264          0.0122     0.0100   -0.0003
  1300        0.0243          0.0102     0.0100   -0.0007
  1400        0.0226          0.0096     0.0100   -0.0008
  1500        0.0211          0.0104     0.0100   -0.0002
  1600        0.0194          0.0095     0.0100   -0.0003
  1700        0.0185          0.0082     0.0100   -0.0002
  1800        0.0174          0.0077     0.0100   -0.0004
  1900        0.0167          0.0071     0.0100   -0.0004
  2000        0.0163          0.0073     0.0100   -0.0002

CV: 3 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986          1.0986     0.0100    0.0308
     2        1.0787          1.0774     0.0100    0.0314
     3        1.0592          1.0563     0.0100    0.0318
     4        1.0406          1.0366     0.0100    0.0301
     5        1.0218          1.0178     0.0100    0.0263
     6        1.0034          0.9978     0.0100    0.0275
     7        0.9857          0.9801     0.0100    0.0236
     8        0.9699          0.9648     0.0100    0.0254
     9        0.9533          0.9469     0.0100    0.0236
    10        0.9371          0.9305     0.0100    0.0256
   100        0.2834          0.2412     0.0100    0.0041
   200        0.1270          0.0803     0.0100    0.0003
   300        0.0845          0.0383     0.0100    0.0001
   400        0.0642          0.0269     0.0100   -0.0000
   500        0.0533          0.0199     0.0100   -0.0008
   600        0.0467          0.0167     0.0100   -0.0000
   700        0.0412          0.0142     0.0100   -0.0004
   800        0.0370          0.0131     0.0100   -0.0004
   900        0.0335          0.0101     0.0100   -0.0001
  1000        0.0296          0.0086     0.0100   -0.0006
  1100        0.0272          0.0075     0.0100   -0.0003
  1200        0.0253          0.0072     0.0100   -0.0004
  1300        0.0237          0.0053     0.0100   -0.0001
  1400        0.0219          0.0047     0.0100   -0.0001
  1500        0.0207          0.0047     0.0100   -0.0005
  1600        0.0193          0.0048     0.0100   -0.0002
  1700        0.0181          0.0047     0.0100   -0.0004
  1800        0.0171          0.0038     0.0100   -0.0002
  1900        0.0159          0.0037     0.0100   -0.0003
  2000        0.0151          0.0042     0.0100   -0.0002

CV: 4 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986          1.0986     0.0100    0.0302
     2        1.0781          1.0775     0.0100    0.0316
     3        1.0576          1.0581     0.0100    0.0299
     4        1.0380          1.0384     0.0100    0.0303
     5        1.0189          1.0192     0.0100    0.0277
     6        1.0001          1.0010     0.0100    0.0266
     7        0.9818          0.9843     0.0100    0.0260
     8        0.9648          0.9670     0.0100    0.0261
     9        0.9476          0.9508     0.0100    0.0244
    10        0.9301          0.9349     0.0100    0.0239
   100        0.2719          0.2905     0.0100    0.0047
   200        0.1107          0.1678     0.0100    0.0007
   300        0.0674          0.1532     0.0100   -0.0006
   400        0.0493          0.1558     0.0100    0.0000
   500        0.0397          0.1691     0.0100    0.0000
   600        0.0313          0.1821     0.0100   -0.0003
   700        0.0252          0.2001     0.0100   -0.0007
   800        0.0212          0.2058     0.0100    0.0001
   900        0.0175          0.2284     0.0100   -0.0005
  1000        0.0145          0.2420     0.0100   -0.0002
  1100        0.0123          0.2526     0.0100   -0.0003
  1200        0.0103          0.2731     0.0100   -0.0001
  1300        0.0089          0.2890     0.0100    0.0000
  1400        0.0077          0.3004     0.0100   -0.0001
  1500        0.0066          0.3189     0.0100   -0.0000
  1600        0.0060          0.3331     0.0100   -0.0001
  1700        0.0053          0.3422     0.0100   -0.0001
  1800        0.0047          0.3494     0.0100   -0.0000
  1900        0.0041          0.3725     0.0100   -0.0000
  2000        0.0036          0.3814     0.0100   -0.0000

CV: 5 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986          1.0986     0.0100    0.0329
     2        1.0781          1.0780     0.0100    0.0294
     3        1.0589          1.0586     0.0100    0.0299
     4        1.0398          1.0392     0.0100    0.0277
     5        1.0213          1.0203     0.0100    0.0287
     6        1.0034          1.0023     0.0100    0.0255
     7        0.9856          0.9837     0.0100    0.0265
     8        0.9684          0.9666     0.0100    0.0253
     9        0.9518          0.9493     0.0100    0.0249
    10        0.9353          0.9323     0.0100    0.0242
   100        0.2737          0.2674     0.0100    0.0047
   200        0.1180          0.1140     0.0100    0.0008
   300        0.0735          0.0804     0.0100   -0.0004
   400        0.0533          0.0710     0.0100   -0.0013
   500        0.0421          0.0685     0.0100   -0.0003
   600        0.0345          0.0670     0.0100   -0.0009
   700        0.0290          0.0747     0.0100   -0.0006
   800        0.0248          0.0792     0.0100   -0.0001
   900        0.0206          0.0854     0.0100   -0.0001
  1000        0.0173          0.0971     0.0100   -0.0002
  1100        0.0144          0.0988     0.0100   -0.0002
  1200        0.0127          0.0992     0.0100   -0.0001
  1300        0.0109          0.1104     0.0100   -0.0002
  1400        0.0090          0.1206     0.0100   -0.0001
  1500        0.0080          0.1209     0.0100   -0.0002
  1600        0.0069          0.1273     0.0100   -0.0002
  1700        0.0060          0.1314     0.0100   -0.0000
  1800        0.0050          0.1401     0.0100   -0.0001
  1900        0.0044          0.1363     0.0100   -0.0001
  2000        0.0039          0.1431     0.0100   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0986             nan     0.0100    0.0315
     2        1.0781             nan     0.0100    0.0292
     3        1.0576             nan     0.0100    0.0287
     4        1.0380             nan     0.0100    0.0295
     5        1.0186             nan     0.0100    0.0281
     6        1.0005             nan     0.0100    0.0253
     7        0.9830             nan     0.0100    0.0267
     8        0.9656             nan     0.0100    0.0269
     9        0.9483             nan     0.0100    0.0243
    10        0.9322             nan     0.0100    0.0237
   100        0.2718             nan     0.0100    0.0046
   200        0.1177             nan     0.0100    0.0006
   300        0.0754             nan     0.0100   -0.0003
   400        0.0566             nan     0.0100    0.0001
   500        0.0480             nan     0.0100   -0.0009
   600        0.0411             nan     0.0100   -0.0001
   700        0.0360             nan     0.0100    0.0000
   800        0.0321             nan     0.0100   -0.0001
   900        0.0289             nan     0.0100   -0.0000
  1000        0.0262             nan     0.0100   -0.0004
  1100        0.0239             nan     0.0100   -0.0007
  1200        0.0221             nan     0.0100   -0.0003
  1300        0.0203             nan     0.0100   -0.0003
  1400        0.0186             nan     0.0100   -0.0002
  1500        0.0175             nan     0.0100   -0.0003
  1600        0.0163             nan     0.0100   -0.0001
  1700        0.0154             nan     0.0100   -0.0003
  1800        0.0144             nan     0.0100   -0.0003
  1900        0.0136             nan     0.0100   -0.0002
  2000        0.0131             nan     0.0100   -0.0002

> iris.mod
gbm(formula = Species ~ ., distribution = "kclass", data = iris, 
    n.trees = 2000, shrinkage = 0.01, cv.folds = 5)
A gradient boosted model with kclass loss function.
2000 iterations were performed.
The best cross-validation iteration was 382.
There were 4 predictors of which 4 had non-zero influence.

Confusion matrix:
           setosa versicolor virginica Pred. Acc.
setosa         50          0         0        100
versicolor      0         47         3         94
virginica       0          1        49         98

Prediction Accuracy = 97.33%
> data( lung )
> lung.mod <- gbm( Surv(time, status) ~ ., distribution="coxph", data=lung,
+                  n.trees=2000, shrinkage=.01, cv.folds=5 )
CV: 1 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        8.6645          5.8132     0.0100   -0.0007
     2        8.6643          5.8133     0.0100   -0.0001
     3        8.6622          5.8129     0.0100    0.0007
     4        8.6599          5.8124     0.0100    0.0007
     5        8.6569          5.8119     0.0100    0.0003
     6        8.6554          5.8094     0.0100    0.0005
     7        8.6532          5.8090     0.0100    0.0006
     8        8.6522          5.8097     0.0100   -0.0002
     9        8.6507          5.8072     0.0100   -0.0001
    10        8.6487          5.8069     0.0100    0.0006
   100        8.5635          5.7737     0.0100   -0.0000
   200        8.4948          5.7707     0.0100   -0.0001
   300        8.4503          5.7707     0.0100   -0.0004
   400        8.4180          5.7674     0.0100   -0.0000
   500        8.3935          5.7733     0.0100   -0.0000
   600        8.3727          5.7928     0.0100   -0.0001
   700        8.3531          5.8124     0.0100    0.0001
   800        8.3409          5.8278     0.0100   -0.0003
   900        8.3246          5.8378     0.0100   -0.0008
  1000        8.3113          5.8359     0.0100    0.0001
  1100        8.3000          5.8434     0.0100    0.0003
  1200        8.2907          5.8613     0.0100   -0.0002
  1300        8.2831          5.8624     0.0100    0.0001
  1400        8.2756          5.8735     0.0100   -0.0002
  1500        8.2681          5.8908     0.0100   -0.0005
  1600        8.2599          5.8928     0.0100   -0.0003
  1700        8.2500          5.8876     0.0100   -0.0008
  1800        8.2405          5.8966     0.0100   -0.0001
  1900        8.2327          5.8916     0.0100   -0.0002
  2000        8.2268          5.9000     0.0100    0.0001

CV: 2 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        8.6520          5.8353     0.0100   -0.0001
     2        8.6501          5.8348     0.0100    0.0003
     3        8.6491          5.8348     0.0100   -0.0002
     4        8.6475          5.8344     0.0100    0.0007
     5        8.6456          5.8339     0.0100    0.0005
     6        8.6437          5.8336     0.0100    0.0005
     7        8.6416          5.8337     0.0100    0.0007
     8        8.6418          5.8364     0.0100   -0.0014
     9        8.6409          5.8371     0.0100    0.0002
    10        8.6398          5.8337     0.0100   -0.0010
   100        8.5405          5.7817     0.0100   -0.0002
   200        8.4815          5.7697     0.0100   -0.0005
   300        8.4388          5.7493     0.0100   -0.0006
   400        8.4086          5.7441     0.0100   -0.0002
   500        8.3858          5.7313     0.0100   -0.0002
   600        8.3659          5.7353     0.0100    0.0001
   700        8.3451          5.7202     0.0100    0.0003
   800        8.3255          5.7210     0.0100   -0.0006
   900        8.3118          5.7162     0.0100   -0.0002
  1000        8.2944          5.7237     0.0100   -0.0001
  1100        8.2783          5.7321     0.0100   -0.0003
  1200        8.2659          5.7473     0.0100   -0.0002
  1300        8.2511          5.7581     0.0100    0.0003
  1400        8.2380          5.7609     0.0100   -0.0000
  1500        8.2271          5.7685     0.0100   -0.0001
  1600        8.2151          5.7623     0.0100   -0.0001
  1700        8.2031          5.7657     0.0100   -0.0001
  1800        8.1924          5.7746     0.0100   -0.0002
  1900        8.1820          5.7830     0.0100   -0.0002
  2000        8.1727          5.7862     0.0100   -0.0002

CV: 3 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        8.6000          6.0433     0.0100   -0.0003
     2        8.5963          6.0399     0.0100    0.0012
     3        8.5957          6.0394     0.0100   -0.0002
     4        8.5941          6.0381     0.0100    0.0005
     5        8.5914          6.0356     0.0100    0.0008
     6        8.5898          6.0351     0.0100    0.0006
     7        8.5894          6.0347     0.0100    0.0001
     8        8.5873          6.0331     0.0100    0.0003
     9        8.5848          6.0318     0.0100    0.0006
    10        8.5829          6.0303     0.0100    0.0004
   100        8.4551          5.9985     0.0100   -0.0001
   200        8.3892          5.9710     0.0100    0.0003
   300        8.3420          5.9728     0.0100   -0.0008
   400        8.3041          5.9871     0.0100   -0.0003
   500        8.2766          5.9928     0.0100   -0.0000
   600        8.2542          6.0078     0.0100   -0.0003
   700        8.2325          6.0167     0.0100   -0.0002
   800        8.2089          6.0291     0.0100   -0.0001
   900        8.1912          6.0410     0.0100    0.0003
  1000        8.1742          6.0485     0.0100   -0.0003
  1100        8.1577          6.0633     0.0100   -0.0006
  1200        8.1469          6.0938     0.0100   -0.0004
  1300        8.1314          6.1057     0.0100    0.0002
  1400        8.1154          6.1174     0.0100   -0.0003
  1500        8.1028          6.1343     0.0100   -0.0003
  1600        8.0911          6.1539     0.0100   -0.0004
  1700        8.0775          6.1662     0.0100   -0.0002
  1800        8.0698          6.1610     0.0100    0.0002
  1900        8.0593          6.1626     0.0100   -0.0006
  2000        8.0504          6.1883     0.0100   -0.0000

CV: 4 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        8.6706          5.7824     0.0100    0.0004
     2        8.6695          5.7815     0.0100    0.0006
     3        8.6672          5.7813     0.0100    0.0007
     4        8.6642          5.7776     0.0100    0.0011
     5        8.6625          5.7764     0.0100    0.0004
     6        8.6607          5.7763     0.0100    0.0008
     7        8.6580          5.7761     0.0100    0.0004
     8        8.6564          5.7755     0.0100    0.0004
     9        8.6536          5.7744     0.0100    0.0000
    10        8.6520          5.7737     0.0100    0.0004
   100        8.5458          5.7220     0.0100    0.0002
   200        8.4761          5.7035     0.0100   -0.0002
   300        8.4284          5.7079     0.0100    0.0003
   400        8.3943          5.7090     0.0100   -0.0001
   500        8.3641          5.7147     0.0100    0.0003
   600        8.3409          5.7196     0.0100   -0.0008
   700        8.3202          5.7265     0.0100   -0.0002
   800        8.3029          5.7366     0.0100   -0.0000
   900        8.2851          5.7438     0.0100   -0.0009
  1000        8.2693          5.7517     0.0100   -0.0010
  1100        8.2523          5.7609     0.0100   -0.0004
  1200        8.2388          5.7764     0.0100   -0.0001
  1300        8.2236          5.7912     0.0100   -0.0009
  1400        8.2119          5.7863     0.0100   -0.0001
  1500        8.2023          5.7918     0.0100   -0.0005
  1600        8.1911          5.7955     0.0100   -0.0002
  1700        8.1791          5.8042     0.0100   -0.0011
  1800        8.1705          5.8079     0.0100   -0.0001
  1900        8.1602          5.8162     0.0100   -0.0008
  2000        8.1523          5.8183     0.0100   -0.0003

CV: 5 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        8.6219          6.0125     0.0100   -0.0003
     2        8.6175          6.0123     0.0100    0.0017
     3        8.6168          6.0122     0.0100    0.0000
     4        8.6140          6.0108     0.0100    0.0009
     5        8.6119          6.0118     0.0100   -0.0009
     6        8.6089          6.0117     0.0100    0.0018
     7        8.6048          6.0117     0.0100    0.0013
     8        8.6004          6.0117     0.0100    0.0018
     9        8.5966          6.0121     0.0100    0.0022
    10        8.5929          6.0123     0.0100    0.0021
   100        8.4467          6.0236     0.0100   -0.0007
   200        8.3823          6.0717     0.0100   -0.0002
   300        8.3459          6.0870     0.0100    0.0001
   400        8.3183          6.1005     0.0100   -0.0001
   500        8.2939          6.0958     0.0100   -0.0003
   600        8.2749          6.1100     0.0100   -0.0005
   700        8.2604          6.1339     0.0100    0.0001
   800        8.2473          6.1461     0.0100   -0.0008
   900        8.2365          6.1206     0.0100    0.0002
  1000        8.2251          6.1420     0.0100   -0.0003
  1100        8.2138          6.1642     0.0100   -0.0005
  1200        8.2046          6.1720     0.0100   -0.0006
  1300        8.1941          6.1796     0.0100   -0.0005
  1400        8.1875          6.1962     0.0100   -0.0000
  1500        8.1787          6.2005     0.0100    0.0001
  1600        8.1711          6.2077     0.0100   -0.0005
  1700        8.1644          6.2184     0.0100   -0.0004
  1800        8.1570          6.2227     0.0100   -0.0005
  1900        8.1498          6.2181     0.0100   -0.0000
  2000        8.1442          6.2097     0.0100   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        9.0864             nan     0.0100    0.0003
     2        9.0838             nan     0.0100    0.0002
     3        9.0820             nan     0.0100    0.0005
     4        9.0804             nan     0.0100    0.0005
     5        9.0782             nan     0.0100    0.0007
     6        9.0747             nan     0.0100    0.0012
     7        9.0725             nan     0.0100    0.0009
     8        9.0718             nan     0.0100   -0.0002
     9        9.0720             nan     0.0100   -0.0007
    10        9.0703             nan     0.0100   -0.0000
   100        8.9732             nan     0.0100    0.0004
   200        8.9079             nan     0.0100   -0.0004
   300        8.8554             nan     0.0100    0.0001
   400        8.8208             nan     0.0100   -0.0004
   500        8.7951             nan     0.0100   -0.0000
   600        8.7750             nan     0.0100   -0.0001
   700        8.7555             nan     0.0100   -0.0006
   800        8.7397             nan     0.0100   -0.0004
   900        8.7266             nan     0.0100   -0.0002
  1000        8.7143             nan     0.0100   -0.0003
  1100        8.7039             nan     0.0100   -0.0004
  1200        8.6930             nan     0.0100   -0.0001
  1300        8.6830             nan     0.0100   -0.0002
  1400        8.6733             nan     0.0100   -0.0005
  1500        8.6645             nan     0.0100   -0.0003
  1600        8.6545             nan     0.0100   -0.0002
  1700        8.6449             nan     0.0100   -0.0008
  1800        8.6377             nan     0.0100    0.0001
  1900        8.6309             nan     0.0100   -0.0000
  2000        8.6241             nan     0.0100   -0.0001

> lung.mod
gbm(formula = Surv(time, status) ~ ., distribution = "coxph", 
    data = lung, n.trees = 2000, shrinkage = 0.01, cv.folds = 5)
A gradient boosted model with coxph loss function.
2000 iterations were performed.
The best cross-validation iteration was 253.
There were 8 predictors of which 8 had non-zero influence.
> 
> 
> 
> cleanEx(); nameEx("quantile.rug")
> ### * quantile.rug
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: quantile.rug
> ### Title: Quantile rug plot
> ### Aliases: quantile.rug
> ### Keywords: aplot
> 
> ### ** Examples
> 
> x <- rnorm(100)
> y <- rnorm(100)
> plot(x,y)
> quantile.rug(x)
> 
> 
> 
> ### * <FOOTER>
> ###
> cat("Time elapsed: ", proc.time() - get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  39.15 0.168 54.304 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
